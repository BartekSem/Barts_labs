{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "362657fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"Data_Marketing_Customer_Analysis_Round3.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c83967",
   "metadata": {},
   "source": [
    "### DATA WRANGLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e18bd51a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10497 entries, 0 to 10688\n",
      "Data columns (total 24 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   region                         10497 non-null  object\n",
      " 1   customer_lifetime_value        10497 non-null  int64 \n",
      " 2   response                       10497 non-null  object\n",
      " 3   coverage                       10497 non-null  object\n",
      " 4   education                      10497 non-null  object\n",
      " 5   effective_to_date              10497 non-null  object\n",
      " 6   month                          10497 non-null  object\n",
      " 7   employment_status              10497 non-null  object\n",
      " 8   gender                         10497 non-null  object\n",
      " 9   income                         10497 non-null  int64 \n",
      " 10  location_code                  10497 non-null  object\n",
      " 11  marital_status                 10497 non-null  object\n",
      " 12  monthly_premium_auto           10497 non-null  int64 \n",
      " 13  months_since_last_claim        10497 non-null  int64 \n",
      " 14  months_since_policy_inception  10497 non-null  int64 \n",
      " 15  number_of_open_complaints      10497 non-null  int64 \n",
      " 16  number_of_policies             10497 non-null  int64 \n",
      " 17  policy_type                    10497 non-null  object\n",
      " 18  policy                         10497 non-null  object\n",
      " 19  renew_offer_type               10497 non-null  object\n",
      " 20  sales_channel                  10497 non-null  object\n",
      " 21  total_claim_amount             10497 non-null  int64 \n",
      " 22  vehicle_class                  10497 non-null  object\n",
      " 23  vehicle_size                   10497 non-null  object\n",
      "dtypes: int64(8), object(16)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df = df.drop_duplicates()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13012ad4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'numericals' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m numericals\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'numericals' is not defined"
     ]
    }
   ],
   "source": [
    "numericals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35793498",
   "metadata": {},
   "source": [
    "### SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c10a44",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Defining x explanatory variables and 1x y traget variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8188fd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"customer_lifetime_value\",\"income\",\"monthly_premium_auto\",\"months_since_last_claim\",\"months_since_policy_inception\",\n",
    "        \"number_of_open_complaints\",\"number_of_policies\"]]\n",
    "y = df[[\"total_claim_amount\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82528181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c91168d",
   "metadata": {},
   "source": [
    "### SCALING WITH PT (PowerTransformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40a9074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCALE VARIABLES AFTER THE SPLIT (NOT TO MIX TEST AND TRAIN DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8703a923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7196557e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, PowerTransformer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9187da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciated the PowerTransformer my my case # \"pt is the scaler \n",
    "pt = PowerTransformer()\n",
    "\n",
    "# Fit the transformer to my X_train data \n",
    "pt = pt.fit(X_train)\n",
    "\n",
    "# Transform X_train using the fitted transformer\n",
    "X_train_trans = pt.transform(X_train)\n",
    "\n",
    "# Transform X_test using the fitted transformer\n",
    "X_test_trans = pt.transform(X_test) \n",
    "\n",
    "# keeps them separately. It also ensures consistency in the transformation process, but only for X! \n",
    "\n",
    "# --------------------WHY DONT WE SCALE Y???? --------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92a4c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c971c4",
   "metadata": {},
   "source": [
    "###  ALTERNATIVE: SCALING WITH STANDARD SCALER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8c77ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the scaler and saving with scaler \n",
    "#scaler = StandardScaler()\n",
    "\n",
    "# create the frame/fit\n",
    "#scaler = scaler.fit(X_train)\n",
    "\n",
    "# populate with data/transform and save in new variables \n",
    "#X_train_trans = scaler.transform(X_train)\n",
    "#X_test_trans = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f03b01",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878544c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4762ea12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i train the model with the transformed training sets from exploring var x and **non-transformed** labels y\n",
    "lm = LinearRegression()\n",
    "model = lm.fit(X_train_trans,y_train) # fitting the model to the data! using the liner functon formula. \n",
    "\n",
    "#creates the linear function line\n",
    "\n",
    "# y_train can be scaled by not in this task. \n",
    "\n",
    "# calculating the line of best fit \n",
    "# the process my test data goes through must be the same train data. e.g. same scaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230c7057",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4b5791",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.intercept_\n",
    "\n",
    "# --------- intercept for what? ---------------- >> the best intercept at the y axe for this linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e8d923",
   "metadata": {},
   "source": [
    "### Model Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ebbf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test_trans)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277d1ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----  is this correct???? do i use the unscaled x_test? why? ----------\n",
    "\n",
    "random_test = X_test.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c20ecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7679d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(random_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d80149d",
   "metadata": {},
   "source": [
    "### Create predictions for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c88806",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e41e6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fe886e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae28a81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resiudals_df = pd.concat([y_test,y_pred],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ede0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_df = resiudals_df.rename(columns={\"total_claim_amount\":\"y_test\", 0:\"y_pred\"})\n",
    "\n",
    "# -------- WHAT IS HAPPENING HERE? --------  NOT ENTIERLY CLEAR ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9431062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_df[\"residual\"] = residuals_df[\"y_test\"]-residuals_df[\"y_pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527caa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(residuals_df,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074ea904",
   "metadata": {},
   "source": [
    "### Calculating metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3649ef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_error = residuals_df[\"residual\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a38d792",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(mean_error,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76816d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse , mean_absolute_error as mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692b5174",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(mse(y_test,y_pred),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61620613",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(mae(y_test,y_pred),2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f641e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rmse = mse(y_test,y_pred, squared = False)\n",
    "round(rmse,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50297836",
   "metadata": {},
   "source": [
    "## Lab instructions 31.01.2024:\n",
    "\n",
    "### - Compute R2 for the first model iteration + feature importance plot\n",
    "### - Run the 2nd iteration of the model, adding the categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8a8fed",
   "metadata": {},
   "source": [
    "### Computing R2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa906028",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a132992b",
   "metadata": {},
   "source": [
    "#### 1/2 Computing R2_score for test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db5918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(r2_score(y_test,y_pred),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d3f568",
   "metadata": {},
   "source": [
    "#### 2/2 Computing R2_score for TRAIN_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a8fa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = pd.DataFrame(model.predict(X_train_trans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a25590",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ded752",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(r2_score(y_train,y_pred_train),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd03cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(r2_score(X_train,y_pred),2)\n",
    "# ERROR HERE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f0a89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(X_train.columns)\n",
    "feature_names\n",
    "\n",
    "coefficients = list(model.coef_)\n",
    "coefficients\n",
    "\n",
    "coefficients = [i for i in coefficients[0]]\n",
    "\n",
    "fi_dict = {\"name\": feature_names, \"coeff\":coefficients}\n",
    "fi_df = pd.DataFrame(fi_dict)\n",
    "fi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84296ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = fi_df[\"name\"], y = fi_df[\"coeff\"])\n",
    "# here we compare the importance of the variables.\n",
    "\n",
    "#---- ONLY WORKS WHEN ALL FOLLOW THE SAME SCALE -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cb6e45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categoricals = ca_df.select_dtypes(include=object)\n",
    "numericals = ca_df.select_dtypes(include = np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2070d3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinals = categoricals[[\"coverage\",\"education\",\"vehicle_size\"]]\n",
    "nominals = categoricals.drop(columns=[\"coverage\",\"education\",\"vehicle_size\",\"effective_to_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9c04c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901638ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinals[\"coverage\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f40959",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OrdinalEncoder(categories=[[\"basic\",\"extended\",\"premium\"]])\n",
    "ordinals[\"coverage\"] = enc.fit_transform(ordinals[[\"coverage\"]])\n",
    "\n",
    "enc = OrdinalEncoder(categories=[[\"college\", \"bachelor\", \"high school or below\", \"doctor\", \"master\"]])\n",
    "ordinals[\"education\"] = enc.fit_transform(ordinals[[\"education\"]])\n",
    "\n",
    "enc = OrdinalEncoder(categories=[[\"medsize\", \"small\", \"large\"]])\n",
    "ordinals[\"vehicle_size\"] = enc.fit_transform(ordinals[[\"vehicle_size\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de6b82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea31136d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nominals = pd.get_dummies(nominals, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755c5eb9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nominals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cbe9be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categorical_coded = pd.concat([ordinals,nominals], axis=1)\n",
    "categorical_coded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e91b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_coded.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5743acdd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final_df = pd.concat([numericals,categorical_coded], axis=1)\n",
    "final_df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d690bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a6b9bb",
   "metadata": {},
   "source": [
    "### SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197b7de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df.drop(columns = [\"total_claim_amount\"])\n",
    "\n",
    "y = final_df[[\"total_claim_amount\"]]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a883e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
